// API endpoint to dynamically discover available AI models
import { NextRequest, NextResponse } from 'next/server';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth';
import { ensureUser, resolveOrgId } from '@/lib/membership';
import { supabaseAdmin } from '@/lib/supabaseAdmin';

import OpenAI from 'openai';
import { GoogleGenerativeAI } from '@google/generative-ai';
import Anthropic from '@anthropic-ai/sdk';

// Model configuration with API key checks and model discovery
interface ModelProvider {
  id: string;
  name: string;
  available: boolean;
  models: ModelInfo[];
  error?: string;
}

interface ModelInfo {
  id: string;
  name: string;
  description?: string;
  contextWindow?: number;
  pricing?: {
    input: number;
    output: number;
  };
}

// Environment variables
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || "";
const GEMINI_API_KEY = process.env.GEMINI_API_KEY || "";
const ANTHROPIC_API_KEY = process.env.ANTHROPIC_API_KEY || "";

// Initialize clients
const openai = OPENAI_API_KEY ? new OpenAI({ apiKey: OPENAI_API_KEY }) : null;
const genAI = GEMINI_API_KEY ? new GoogleGenerativeAI(GEMINI_API_KEY) : null;
const anthropic = ANTHROPIC_API_KEY ? new Anthropic({ apiKey: ANTHROPIC_API_KEY }) : null;

async function discoverOpenAIModels(): Promise<ModelInfo[]> {
  if (!openai) return [];
  
  try {
    // For OpenAI, we'll use a curated list of production models
    // since the models API requires special permissions
    return [
      {
        id: 'gpt-4o',
        name: 'GPT-4o',
        description: 'Most capable model, great for complex tasks',
        contextWindow: 128000,
        pricing: { input: 5.00, output: 15.00 }
      },
      {
        id: 'gpt-4o-mini',
        name: 'GPT-4o Mini',
        description: 'Fast and efficient for most tasks',
        contextWindow: 128000,
        pricing: { input: 0.15, output: 0.60 }
      },
      {
        id: 'gpt-4-turbo',
        name: 'GPT-4 Turbo',
        description: 'High performance model with large context',
        contextWindow: 128000,
        pricing: { input: 10.00, output: 30.00 }
      },
      {
        id: 'gpt-3.5-turbo',
        name: 'GPT-3.5 Turbo',
        description: 'Fast and cost-effective',
        contextWindow: 16385,
        pricing: { input: 0.50, output: 1.50 }
      }
    ];
  } catch (error) {
    console.error('OpenAI model discovery failed:', error);
    return [];
  }
}

async function discoverGeminiModels(): Promise<ModelInfo[]> {
  if (!genAI) return [];
  
  try {
    // Use the actual ListModels API to get real available models
    const response = await fetch('https://generativelanguage.googleapis.com/v1beta/models?key=' + process.env.GEMINI_API_KEY);
    
    if (!response.ok) {
      throw new Error(`ListModels API failed: ${response.status} ${response.statusText}`);
    }
    
    const data = await response.json();
    const availableModels: ModelInfo[] = [];
    
    console.log('🔍 GEMINI DEBUG - Available models from API:', data.models?.map((m: any) => m.name) || []);
    
    if (data.models) {
      // Try to find models that support generation and are commonly available
      const preferredModels = [
        'gemini-2.0-flash',
        'gemini-1.5-flash', 
        'gemini-1.5-pro',
        'gemini-pro'
      ];
      
      for (const preferredModel of preferredModels) {
        const foundModel = data.models.find((m: any) => 
          m.name === `models/${preferredModel}` && 
          (m.supportedGenerationMethods?.includes('generateContent') || 
           m.supportedGenerationMethods?.includes('streamGenerateContent'))
        );
        
        if (foundModel) {
          const modelInfo = getGeminiModelInfo(preferredModel);
          if (modelInfo) {
            availableModels.push(modelInfo);
            console.log(`✅ Gemini ${preferredModel} available and supports generation`);
            // Only add the first working model to avoid confusion
            break;
          }
        }
      }
    }
    
    if (availableModels.length === 0) {
      console.warn('No preferred Gemini models support generation with this API key');
      return [];
    }
    
    return availableModels;
  } catch (error: any) {
    console.error('Gemini model discovery failed:', error);
    return [];
  }
}

function getGeminiModelInfo(modelId: string): ModelInfo | null {
  const modelMap: Record<string, ModelInfo> = {
    'gemini-2.0-flash': {
      id: 'gemini-2.0-flash',
      name: 'Gemini 2.0 Flash',
      description: 'Latest and most advanced Gemini model',
      contextWindow: 1000000,
      pricing: { input: 0.075, output: 0.30 }
    },
    'gemini-1.5-pro': {
      id: 'gemini-1.5-pro',
      name: 'Gemini 1.5 Pro',
      description: 'Most capable Gemini model',
      contextWindow: 2000000,
      pricing: { input: 3.50, output: 10.50 }
    },
    'gemini-1.5-flash': {
      id: 'gemini-1.5-flash',
      name: 'Gemini 1.5 Flash',
      description: 'Fast and efficient',
      contextWindow: 1000000,
      pricing: { input: 0.075, output: 0.30 }
    },
    'gemini-pro': {
      id: 'gemini-pro',
      name: 'Gemini Pro',
      description: 'Balanced performance',
      contextWindow: 32768,
      pricing: { input: 0.50, output: 1.50 }
    }
  };
  
  return modelMap[modelId] || null;
}

function getGeminiFallbackModels(): ModelInfo[] {
  return [
    {
      id: 'gemini-1.5-flash',
      name: 'Gemini 1.5 Flash',
      description: 'Fast and efficient',
      contextWindow: 1000000,
      pricing: { input: 0.075, output: 0.30 }
    },
    {
      id: 'gemini-pro',
      name: 'Gemini Pro',
      description: 'Balanced performance',
      contextWindow: 32768,
      pricing: { input: 0.50, output: 1.50 }
    }
  ];
}

async function discoverAnthropicModels(): Promise<ModelInfo[]> {
  if (!anthropic) return [];
  
  // Test which Claude models actually work with this API key
  const potentialModels = [
    {
      id: 'claude-3-5-sonnet-20241022',
      name: 'Claude 3.5 Sonnet',
      description: 'Most capable model for complex tasks',
      contextWindow: 200000,
      pricing: { input: 3.00, output: 15.00 }
    },
    {
      id: 'claude-3-5-sonnet-20240620',
      name: 'Claude 3.5 Sonnet (June)',
      description: 'Previous version of Claude 3.5 Sonnet',
      contextWindow: 200000,
      pricing: { input: 3.00, output: 15.00 }
    },
    {
      id: 'claude-3-opus-20240229',
      name: 'Claude 3 Opus',
      description: 'Most powerful model for complex reasoning',
      contextWindow: 200000,
      pricing: { input: 15.00, output: 75.00 }
    },
    {
      id: 'claude-3-sonnet-20240229',
      name: 'Claude 3 Sonnet',
      description: 'Balanced performance and speed',
      contextWindow: 200000,
      pricing: { input: 3.00, output: 15.00 }
    },
    {
      id: 'claude-3-haiku-20240307',
      name: 'Claude 3 Haiku',
      description: 'Fastest model for simple tasks',
      contextWindow: 200000,
      pricing: { input: 0.25, output: 1.25 }
    }
  ];
  
  const availableModels: ModelInfo[] = [];
  
  // Test each model with a simple request to see which ones work
  for (const model of potentialModels) {
    try {
      await anthropic.messages.create({
        model: model.id,
        max_tokens: 10,
        messages: [{ role: 'user', content: 'Hi' }]
      });
      availableModels.push(model);
      console.log(`✅ Claude ${model.name} available and working`);
      
      // For now, only return the first working model to avoid rate limits
      break;
    } catch (error: any) {
      console.log(`❌ Claude ${model.name} not available: ${error.message}`);
      continue;
    }
  }
  
  if (availableModels.length === 0) {
    console.warn('No Claude models are accessible with this API key');
  }
  
  return availableModels;
}

async function loadTenantModelSettings(orgId: string) {
  const { data, error } = await supabaseAdmin
    .from('tenant_settings')
    .select('value')
    .eq('org_id', orgId)
    .eq('key', 'modelEnabled')
    .single();
  
  if (error || !data) {
    // Default to all enabled if no settings found
    return { openai: true, gemini: true, anthropic: true };
  }
  
  return data.value as { openai: boolean; gemini: boolean; anthropic: boolean };
}

export async function GET(request: NextRequest) {
  try {
    const session = await getServerSession(authOptions);
    if (!session) {
      return NextResponse.json(
        { success: false, error: 'Authentication required' },
        { status: 401 }
      );
    }

    const userId = await ensureUser(session);
    const orgId = await resolveOrgId(userId);
    
    // Load tenant model settings
    const modelSettings = await loadTenantModelSettings(orgId);
    
    // Discover available models for each provider
    const providers: ModelProvider[] = [];
    
    // OpenAI
    if (modelSettings.openai) {
      const openaiModels = await discoverOpenAIModels();
      providers.push({
        id: 'openai',
        name: 'OpenAI',
        available: openaiModels.length > 0,
        models: openaiModels,
        error: openaiModels.length === 0 ? 'API key not configured or invalid' : undefined
      });
    }
    
    // Google Gemini
    if (modelSettings.gemini) {
      const geminiModels = await discoverGeminiModels();
      providers.push({
        id: 'gemini',
        name: 'Google Gemini',
        available: geminiModels.length > 0,
        models: geminiModels,
        error: geminiModels.length === 0 ? 'API key not configured or quota exceeded' : undefined
      });
    }
    
    // Anthropic Claude
    if (modelSettings.anthropic) {
      const anthropicModels = await discoverAnthropicModels();
      providers.push({
        id: 'anthropic',
        name: 'Anthropic',
        available: anthropicModels.length > 0,
        models: anthropicModels,
        error: anthropicModels.length === 0 ? 'API key not configured or invalid' : undefined
      });
    }
    
    // Flatten models for easy dropdown consumption
    const allModels = providers.flatMap(provider => 
      provider.models.map(model => ({
        id: model.id,
        name: `${provider.name} ${model.name}`,
        provider: provider.id,
        description: model.description,
        contextWindow: model.contextWindow,
        pricing: model.pricing,
        available: provider.available
      }))
    );
    
    return NextResponse.json({
      success: true,
      providers,
      models: allModels,
      defaultModel: allModels.find(m => m.available)?.id || null
    });
    
  } catch (error: any) {
    console.error('GET /api/models error:', error);
    return NextResponse.json(
      { success: false, error: error.message },
      { status: 500 }
    );
  }
}
